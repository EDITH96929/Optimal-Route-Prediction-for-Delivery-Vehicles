# ğŸšš Optimal Route Prediction for Delivery Vehicles

### ğŸ“˜ Domain Project | AI & Machine Learning

**Objective:** Predict the *fastest* and *most fuel-efficient* delivery routes across Bhubaneswar using **Graph Algorithms** and **Reinforcement Learning (RL)**.
Developed with Python, Streamlit, and Q-Learning.

---

## ğŸ§­ Project Overview

This project simulates a smart delivery route optimizer for logistics systems in Bhubaneswar city.
It automatically computes the most efficient path for one or multiple deliveries using:

* **Graph Algorithms** (Dijkstra, TSP)
* **Reinforcement Learning** (Q-Learning agent)
* **GUI Visualization** with Streamlit

The model can optimize based on **distance**, **travel time**, or **fuel consumption**.

---

## ğŸ¯ Objectives

* Predict optimal routes between delivery points.
* Reduce travel time and fuel cost.
* Provide an interactive GUI to visualize routes.
* Implement a learning-based route predictor using Reinforcement Learning.

---

## ğŸ§± System Architecture

```
delivery-optimizer/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ bhubaneswar_graph.json          # Realistic city graph dataset
â”‚
â”œâ”€â”€ algorithms/
â”‚   â”œâ”€â”€ dijkstra.py                     # Shortest path algorithm
â”‚   â””â”€â”€ tsp_solver.py                   # Multi-stop (TSP) optimization
â”‚
â”œâ”€â”€ rl_agent/
â”‚   â”œâ”€â”€ environment.py                  # RL environment (Delivery simulator)
â”‚   â””â”€â”€ agent.py                        # Q-learning route agent
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ graph_generator.py              # Generates Bhubaneswar road dataset
â”‚
â”œâ”€â”€ gui/
â”‚   â””â”€â”€ app.py                          # Streamlit GUI interface
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ q_table.pkl                     # Saved trained RL model
â”‚
â””â”€â”€ requirements.txt
```

---

## ğŸ—ºï¸ Data Description

**Dataset:** Generated synthetic Bhubaneswar road network with real landmark names.

Each road (edge) includes:

| Feature     | Description                  |
| ----------- | ---------------------------- |
| `distance`  | Distance in km               |
| `time`      | Estimated travel time (mins) |
| `fuel_cost` | Fuel consumption (liters)    |

**Nodes (locations):**
Master Canteen Square, Ram Mandir Square, KIIT Square, Airport, Kalpana Square, Baramunda, etc.

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone or download the project

```bash
git clone https://github.com/<your-username>/delivery-optimizer.git
cd delivery-optimizer
```

### 2ï¸âƒ£ Create virtual environment & install dependencies

```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ Generate Bhubaneswar dataset

```bash
python utils/graph_generator.py
```

### 4ï¸âƒ£ Launch GUI

```bash
streamlit run gui/app.py
```

---

## ğŸ’» How It Works

| Mode                       | Description                                                                                   |
| -------------------------- | --------------------------------------------------------------------------------------------- |
| **Graph Algorithm**        | Uses **Dijkstraâ€™s Algorithm** to compute the shortest route between two points.               |
| **Multi-Delivery (TSP)**   | Finds the best visiting order for multiple delivery stops (Travelling Salesman Problem).      |
| **Reinforcement Learning** | Uses **Q-Learning** to train an AI agent that learns optimal routing through trial and error. |

---

## ğŸ§  Reinforcement Learning Logic

| Concept        | Explanation                                  |
| -------------- | -------------------------------------------- |
| **State (s)**  | Current delivery location                    |
| **Action (a)** | Next location to move to                     |
| **Reward (r)** | Negative of travel cost (distance/time/fuel) |
| **Goal**       | Reach the target while minimizing total cost |

RL Algorithm:
[
Q(s,a) = Q(s,a) + Î± [r + Î³ \max Q(s', a') - Q(s,a)]
]

---

## ğŸ§© Technologies Used

| Component     | Tool / Library                   |
| ------------- | -------------------------------- |
| Language      | Python                           |
| Visualization | Streamlit, Matplotlib, NetworkX  |
| Algorithms    | Dijkstra, TSP, Q-Learning        |
| Environment   | DeliveryRouteEnv (custom)        |
| Data          | Synthetic Bhubaneswar city graph |

---

## ğŸš€ Output Preview

### ğŸ—ºï¸ Modes

* **Graph Algorithm** â†’ Single route (Dijkstra)
* **Multi-Delivery** â†’ Multiple stops (TSP)
* **Reinforcement Learning** â†’ Learned optimal policy

### ğŸ–¼ï¸ GUI Preview

* Select **start** and **destination**
* Choose **metric** (distance/time/fuel)
* Click **Find Route**
* View route visualization on Bhubaneswar map (Graph view)

---

## ğŸ“Š Sample Output

```
ğŸšš Optimal route from Master Canteen Square â†’ KIIT Square (distance):
Master Canteen Square â†’ Ram Mandir Square â†’ Acharya Vihar â†’ Jayadev Vihar â†’ KIIT Square
Total distance: 12.85 km
```

```
ğŸ§  RL Agent Trained (1000 episodes)
Predicted optimal route:
Master Canteen Square â†’ Ram Mandir Square â†’ KIIT Square
Total fuel_cost: 0.97 liters
```

---

## ğŸ—ï¸ Future Improvements

* Integrate **real map visualization** (OpenStreetMap / Folium)
* Add **live traffic API** for dynamic route optimization
* Support **multiple vehicles**
* Deploy on **Streamlit Cloud / AWS**

---

## ğŸ§‘â€ğŸ’» Contributors

| Name                   | Role                              |
| ---------------------- | --------------------------------- |
| Sunil Kumar Swain      | AI/ML Developer, Project Lead     |
| College Domain Project | B.Tech (Computer Science / AI-ML) |

---

## ğŸ“š References

* *Artificial Intelligence: A Modern Approach* â€“ Russell & Norvig
* NetworkX Documentation: [https://networkx.org](https://networkx.org)
* Streamlit Documentation: [https://streamlit.io](https://streamlit.io)
* Sutton & Barto â€“ *Reinforcement Learning: An Introduction*

---

## ğŸ Conclusion

This project demonstrates how **graph theory** and **reinforcement learning** can be combined to optimize real-world delivery logistics.
It not only predicts the **shortest** and **most efficient** routes but also showcases how an AI agent can **learn and adapt** to dynamic conditions in a delivery network.

**âœ… Project Completed Successfully**
